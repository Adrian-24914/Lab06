/**
 * Universidad del Valle de Guatemala
 * CC3086 Programaci√≥n de Microprocesadores
 * Laboratorio 6 - Pr√°ctica 5: Pipeline con Barreras y pthread_once
 * 
 * Autor: Adrian Penagos
 * Fecha: Septiembre 2025
 * Prop√≥sito: Construir pipeline de 3 etapas sincronizado con barriers
 *           Inicializaci√≥n √∫nica con pthread_once y medici√≥n de throughput
 */

#include <pthread.h>
#include <cstdio>
#include <cstdlib>
#include <chrono>
#include <vector>
#include <queue>
#include <fstream>
#include <cassert>
#include <unistd.h>
#include <random>
#include <cstring>
#include <cmath>  

// ============================================================================
// CONSTANTES Y CONFIGURACI√ìN DEL PIPELINE
// ============================================================================

constexpr int DEFAULT_TICKS = 1000;        // N√∫mero de iteraciones del pipeline
constexpr int BUFFER_SIZE = 100;           // Tama√±o de b√∫fers entre etapas
constexpr int DATA_RANGE = 10000;          // Rango de datos a procesar

// Tipos de datos que fluyen por el pipeline
struct DataItem {
    int id;                    // Identificador √∫nico
    int raw_value;            // Valor original (etapa 1)
    double processed_value;   // Valor procesado (etapa 2)  
    bool is_valid;            // Resultado de filtrado (etapa 3)
    std::chrono::steady_clock::time_point timestamp;  // Para medir latencia
    
    DataItem() : id(-1), raw_value(0), processed_value(0.0), is_valid(false) {}
    DataItem(int _id, int _val) : id(_id), raw_value(_val), processed_value(0.0), 
                                  is_valid(false), timestamp(std::chrono::steady_clock::now()) {}
};

// ============================================================================
// RECURSOS COMPARTIDOS Y SINCRONIZACI√ìN
// ============================================================================

// Barrier para sincronizaci√≥n entre etapas
static pthread_barrier_t pipeline_barrier;

// pthread_once para inicializaci√≥n √∫nica
static pthread_once_t once_flag = PTHREAD_ONCE_INIT;

// B√∫fers entre etapas (protegidos por mutex)
static std::queue<DataItem> stage1_to_stage2;
static std::queue<DataItem> stage2_to_stage3;
static pthread_mutex_t buffer1_mutex = PTHREAD_MUTEX_INITIALIZER;
static pthread_mutex_t buffer2_mutex = PTHREAD_MUTEX_INITIALIZER;

// Condici√≥n para se√±alizar datos disponibles/espacio disponible
static pthread_cond_t buffer1_not_empty = PTHREAD_COND_INITIALIZER;
static pthread_cond_t buffer1_not_full = PTHREAD_COND_INITIALIZER;
static pthread_cond_t buffer2_not_empty = PTHREAD_COND_INITIALIZER;
static pthread_cond_t buffer2_not_full = PTHREAD_COND_INITIALIZER;

// Control de terminaci√≥n del pipeline
static bool pipeline_shutdown = false;
static pthread_mutex_t shutdown_mutex = PTHREAD_MUTEX_INITIALIZER;

// Recursos compartidos globales (inicializados una sola vez)
static std::ofstream* log_file = nullptr;
static std::mt19937* global_rng = nullptr;
static double* lookup_table = nullptr;

// Estad√≠sticas globales del pipeline
struct PipelineStats {
    long items_generated = 0;
    long items_processed = 0;
    long items_filtered = 0;
    long barrier_waits = 0;
    double total_latency_ms = 0.0;
    pthread_mutex_t stats_mutex = PTHREAD_MUTEX_INITIALIZER;
    
    void add_latency(double latency_ms) {
        pthread_mutex_lock(&stats_mutex);
        total_latency_ms += latency_ms;
        pthread_mutex_unlock(&stats_mutex);
    }
    
    void print_final_stats() {
        pthread_mutex_lock(&stats_mutex);
        printf("\n=== ESTAD√çSTICAS FINALES DEL PIPELINE ===\n");
        printf("Items generados:   %ld\n", items_generated);
        printf("Items procesados:  %ld\n", items_processed);
        printf("Items filtrados:   %ld (%.1f%%)\n", items_filtered, 
               100.0 * items_filtered / items_generated);
        printf("Esperas en barrier: %ld\n", barrier_waits);
        printf("Latencia promedio: %.2f ms\n", 
               items_filtered > 0 ? total_latency_ms / items_filtered : 0.0);
        pthread_mutex_unlock(&stats_mutex);
    }
} pipeline_stats;

// ============================================================================
// INICIALIZACI√ìN √öNICA CON PTHREAD_ONCE
// ============================================================================

/**
 * Funci√≥n de inicializaci√≥n ejecutada UNA SOLA VEZ
 * pthread_once garantiza que solo un hilo ejecute esta funci√≥n
 */
static void init_shared_resources() {
    printf("üîß Inicializando recursos compartidos (pthread_once)...\n");
    
    // Abrir archivo de log para el pipeline
    log_file = new std::ofstream("data/pipeline_log.txt");
    if (log_file->is_open()) {
        *log_file << "Pipeline Log - Timestamp: " 
                  << std::chrono::duration_cast<std::chrono::seconds>(
                       std::chrono::system_clock::now().time_since_epoch()).count()
                  << std::endl;
        *log_file << "Stage,ItemID,Value,Timestamp" << std::endl;
        printf("‚úÖ Archivo de log abierto exitosamente\n");
    } else {
        printf("‚ùå Error abriendo archivo de log\n");
    }
    
    // Inicializar generador de n√∫meros aleatorios global
    global_rng = new std::mt19937(42);  // Semilla fija para reproducibilidad
    printf("‚úÖ Generador RNG inicializado\n");
    
    // Crear tabla de lookup para optimizar c√°lculos en etapa 2
    lookup_table = new double[DATA_RANGE];
    for (int i = 0; i < DATA_RANGE; i++) {
        // Funci√≥n costosa de calcular: sqrt(sin(x)^2 + cos(x)^2) = 1, pero simulamos c√≥mputo
        lookup_table[i] = sqrt(sin(i * 0.001) * sin(i * 0.001) + 
                             cos(i * 0.001) * cos(i * 0.001));
    }
    printf("‚úÖ Tabla de lookup precalculada (%d entradas)\n", DATA_RANGE);
    
    printf("üéØ Inicializaci√≥n √∫nica completada exitosamente\n");
}

// ============================================================================
// FUNCIONES AUXILIARES PARA B√öFERS
// ============================================================================

/**
 * Insertar item en b√∫fer entre etapas 1 y 2
 */
bool push_to_buffer1(const DataItem& item, int timeout_ms = 1000) {
    struct timespec abs_timeout;
    clock_gettime(CLOCK_REALTIME, &abs_timeout);
    abs_timeout.tv_sec += timeout_ms / 1000;
    abs_timeout.tv_nsec += (timeout_ms % 1000) * 1000000;
    if (abs_timeout.tv_nsec >= 1000000000) {
        abs_timeout.tv_sec++;
        abs_timeout.tv_nsec -= 1000000000;
    }
    
    pthread_mutex_lock(&buffer1_mutex);
    
    // Esperar espacio disponible
    while (stage1_to_stage2.size() >= BUFFER_SIZE && !pipeline_shutdown) {
        if (pthread_cond_timedwait(&buffer1_not_full, &buffer1_mutex, &abs_timeout) != 0) {
            pthread_mutex_unlock(&buffer1_mutex);
            return false;  // Timeout
        }
    }
    
    if (pipeline_shutdown) {
        pthread_mutex_unlock(&buffer1_mutex);
        return false;
    }
    
    stage1_to_stage2.push(item);
    pthread_cond_signal(&buffer1_not_empty);
    pthread_mutex_unlock(&buffer1_mutex);
    
    // Log de la operaci√≥n
    if (log_file && log_file->is_open()) {
        *log_file << "Stage1," << item.id << "," << item.raw_value << "," 
                  << std::chrono::duration_cast<std::chrono::milliseconds>(
                       std::chrono::steady_clock::now().time_since_epoch()).count() 
                  << std::endl;
    }
    
    return true;
}

/**
 * Extraer item del b√∫fer entre etapas 1 y 2
 */
bool pop_from_buffer1(DataItem& item, int timeout_ms = 1000) {
    struct timespec abs_timeout;
    clock_gettime(CLOCK_REALTIME, &abs_timeout);
    abs_timeout.tv_sec += timeout_ms / 1000;
    abs_timeout.tv_nsec += (timeout_ms % 1000) * 1000000;
    if (abs_timeout.tv_nsec >= 1000000000) {
        abs_timeout.tv_sec++;
        abs_timeout.tv_nsec -= 1000000000;
    }
    
    pthread_mutex_lock(&buffer1_mutex);
    
    while (stage1_to_stage2.empty() && !pipeline_shutdown) {
        if (pthread_cond_timedwait(&buffer1_not_empty, &buffer1_mutex, &abs_timeout) != 0) {
            pthread_mutex_unlock(&buffer1_mutex);
            return false;  // Timeout
        }
    }
    
    if (stage1_to_stage2.empty()) {
        pthread_mutex_unlock(&buffer1_mutex);
        return false;
    }
    
    item = stage1_to_stage2.front();
    stage1_to_stage2.pop();
    pthread_cond_signal(&buffer1_not_full);
    pthread_mutex_unlock(&buffer1_mutex);
    
    return true;
}

/**
 * Insertar item en b√∫fer entre etapas 2 y 3
 */
bool push_to_buffer2(const DataItem& item, int timeout_ms = 1000) {
    struct timespec abs_timeout;
    clock_gettime(CLOCK_REALTIME, &abs_timeout);
    abs_timeout.tv_sec += timeout_ms / 1000;
    abs_timeout.tv_nsec += (timeout_ms % 1000) * 1000000;
    if (abs_timeout.tv_nsec >= 1000000000) {
        abs_timeout.tv_sec++;
        abs_timeout.tv_nsec -= 1000000000;
    }
    
    pthread_mutex_lock(&buffer2_mutex);
    
    while (stage2_to_stage3.size() >= BUFFER_SIZE && !pipeline_shutdown) {
        if (pthread_cond_timedwait(&buffer2_not_full, &buffer2_mutex, &abs_timeout) != 0) {
            pthread_mutex_unlock(&buffer2_mutex);
            return false;  // Timeout
        }
    }
    
    if (pipeline_shutdown) {
        pthread_mutex_unlock(&buffer2_mutex);
        return false;
    }
    
    stage2_to_stage3.push(item);
    pthread_cond_signal(&buffer2_not_empty);
    pthread_mutex_unlock(&buffer2_mutex);
    
    if (log_file && log_file->is_open()) {
        *log_file << "Stage2," << item.id << "," << item.processed_value << "," 
                  << std::chrono::duration_cast<std::chrono::milliseconds>(
                       std::chrono::steady_clock::now().time_since_epoch()).count() 
                  << std::endl;
    }
    
    return true;
}

/**
 * Extraer item del b√∫fer entre etapas 2 y 3
 */
bool pop_from_buffer2(DataItem& item, int timeout_ms = 1000) {
    struct timespec abs_timeout;
    clock_gettime(CLOCK_REALTIME, &abs_timeout);
    abs_timeout.tv_sec += timeout_ms / 1000;
    abs_timeout.tv_nsec += (timeout_ms % 1000) * 1000000;
    if (abs_timeout.tv_nsec >= 1000000000) {
        abs_timeout.tv_sec++;
        abs_timeout.tv_nsec -= 1000000000;
    }
    
    pthread_mutex_lock(&buffer2_mutex);
    
    while (stage2_to_stage3.empty() && !pipeline_shutdown) {
        if (pthread_cond_timedwait(&buffer2_not_empty, &buffer2_mutex, &abs_timeout) != 0) {
            pthread_mutex_unlock(&buffer2_mutex);
            return false;  // Timeout
        }
    }
    
    if (stage2_to_stage3.empty()) {
        pthread_mutex_unlock(&buffer2_mutex);
        return false;
    }
    
    item = stage2_to_stage3.front();
    stage2_to_stage3.pop();
    pthread_cond_signal(&buffer2_not_full);
    pthread_mutex_unlock(&buffer2_mutex);
    
    return true;
}

// ============================================================================
// ETAPAS DEL PIPELINE
// ============================================================================

/**
 * ETAPA 1: GENERADOR
 * Genera datos de entrada para el pipeline
 */
void* stage_generator(void* arg) {
    long stage_id = reinterpret_cast<long>(arg);
    int ticks = DEFAULT_TICKS;
    
    printf("[Etapa %ld - Generador] Iniciado\n", stage_id);
    
    // Ejecutar inicializaci√≥n √∫nica
    pthread_once(&once_flag, init_shared_resources);
    
    std::uniform_int_distribution<int> value_dist(1, DATA_RANGE);
    
    for (int tick = 0; tick < ticks; tick++) {
        // Generar nuevo item de datos
        int raw_value = value_dist(*global_rng);
        DataItem item(tick, raw_value);
        
        // Intentar insertar en b√∫fer hacia etapa 2
        if (!push_to_buffer1(item)) {
            printf("[Etapa %ld] Timeout/Error enviando item %d\n", stage_id, tick);
            break;
        }
        
        // Actualizar estad√≠sticas
        pthread_mutex_lock(&pipeline_stats.stats_mutex);
        pipeline_stats.items_generated++;
        pthread_mutex_unlock(&pipeline_stats.stats_mutex);
        
        // Log peri√≥dico
        if (tick % 100 == 0) {
            printf("[Etapa %ld] Generados %d items\n", stage_id, tick + 1);
        }
        
        // Sincronizaci√≥n con barrier
        pthread_mutex_lock(&pipeline_stats.stats_mutex);
        pipeline_stats.barrier_waits++;
        pthread_mutex_unlock(&pipeline_stats.stats_mutex);
        
        int barrier_result = pthread_barrier_wait(&pipeline_barrier);
        if (barrier_result != 0 && barrier_result != PTHREAD_BARRIER_SERIAL_THREAD) {
            printf("[Etapa %ld] Error en barrier: %d\n", stage_id, barrier_result);
        }
        
        // Peque√±a pausa para simular trabajo de generaci√≥n
        usleep(1000);  // 1ms
    }
    
    printf("[Etapa %ld - Generador] Completado - %d items generados\n", stage_id, ticks);
    return nullptr;
}

/**
 * ETAPA 2: PROCESADOR
 * Aplica transformaciones complejas a los datos
 */
void* stage_processor(void* arg) {
    long stage_id = reinterpret_cast<long>(arg);
    int processed_count = 0;
    
    printf("[Etapa %ld - Procesador] Iniciado\n", stage_id);
    
    // Ejecutar inicializaci√≥n √∫nica
    pthread_once(&once_flag, init_shared_resources);
    
    for (int tick = 0; tick < DEFAULT_TICKS; tick++) {
        DataItem item;
        
        // Obtener item del b√∫fer de entrada
        if (!pop_from_buffer1(item)) {
            printf("[Etapa %ld] Timeout obteniendo item en tick %d\n", stage_id, tick);
            break;
        }
        
        // PROCESAMIENTO INTENSIVO:
        // 1. Aplicar funci√≥n compleja usando tabla de lookup
        double base_value = lookup_table[item.raw_value % DATA_RANGE];
        
        // 2. Aplicar transformaciones matem√°ticas
        item.processed_value = base_value * log(item.raw_value + 1);
        item.processed_value += sin(item.raw_value * 0.01) * cos(item.id * 0.02);
        
        // 3. Normalizaci√≥n
        item.processed_value = fabs(item.processed_value);
        
        // Simular c√≥mputo intensivo
        volatile double temp = 0.0;
        for (int i = 0; i < 1000; i++) {
            temp += sqrt(i + item.raw_value);
        }
        item.processed_value += temp * 1e-6;  // Agregar resultado para evitar optimizaci√≥n
        
        processed_count++;
        
        // Enviar a la siguiente etapa
        if (!push_to_buffer2(item)) {
            printf("[Etapa %ld] Error enviando item procesado %d\n", stage_id, item.id);
            break;
        }
        
        // Actualizar estad√≠sticas
        pthread_mutex_lock(&pipeline_stats.stats_mutex);
        pipeline_stats.items_processed++;
        pthread_mutex_unlock(&pipeline_stats.stats_mutex);
        
        if (processed_count % 100 == 0) {
            printf("[Etapa %ld] Procesados %d items\n", stage_id, processed_count);
        }
        
        // Sincronizaci√≥n con barrier
        pthread_mutex_lock(&pipeline_stats.stats_mutex);
        pipeline_stats.barrier_waits++;
        pthread_mutex_unlock(&pipeline_stats.stats_mutex);
        
        pthread_barrier_wait(&pipeline_barrier);
    }
    
    printf("[Etapa %ld - Procesador] Completado - %d items procesados\n", 
           stage_id, processed_count);
    return nullptr;
}

/**
 * ETAPA 3: FILTRO Y REDUCTOR
 * Filtra datos v√°lidos y los agrega a resultado final
 */
void* stage_filter_reduce(void* arg) {
    long stage_id = reinterpret_cast<long>(arg);
    int filtered_count = 0;
    double accumulated_result = 0.0;
    
    printf("[Etapa %ld - Filtro/Reduce] Iniciado\n", stage_id);
    
    // Ejecutar inicializaci√≥n √∫nica
    pthread_once(&once_flag, init_shared_resources);
    
    for (int tick = 0; tick < DEFAULT_TICKS; tick++) {
        DataItem item;
        
        // Obtener item del b√∫fer de entrada
        if (!pop_from_buffer2(item)) {
            printf("[Etapa %ld] Timeout obteniendo item en tick %d\n", stage_id, tick);
            break;
        }
        
        // FILTRADO: Solo aceptar items que cumplan criterios
        bool passes_filter = false;
        
        // Criterio 1: Valor procesado dentro de rango v√°lido
        if (item.processed_value > 0.1 && item.processed_value < 100.0) {
            // Criterio 2: ID no divisible por 13 (superstici√≥n del pipeline)
            if (item.id % 13 != 0) {
                // Criterio 3: Valor original cumple alg√∫n patr√≥n
                if ((item.raw_value % 3 == 0) || (item.raw_value % 7 == 0)) {
                    passes_filter = true;
                }
            }
        }
        
        if (passes_filter) {
            item.is_valid = true;
            filtered_count++;
            
            // REDUCCI√ìN: Agregar al resultado acumulado
            accumulated_result += item.processed_value;
            
            // Calcular latencia end-to-end
            auto now = std::chrono::steady_clock::now();
            double latency_ms = std::chrono::duration<double, std::milli>(
                now - item.timestamp).count();
            
            pipeline_stats.add_latency(latency_ms);
            
            // Log del item filtrado
            if (log_file && log_file->is_open()) {
                *log_file << "Stage3," << item.id << "," << item.processed_value << "," 
                          << std::chrono::duration_cast<std::chrono::milliseconds>(
                               now.time_since_epoch()).count() 
                          << " (VALID, latency=" << latency_ms << "ms)" << std::endl;
            }
        } else {
            item.is_valid = false;
        }
        
        // Actualizar estad√≠sticas
        if (item.is_valid) {
            pthread_mutex_lock(&pipeline_stats.stats_mutex);
            pipeline_stats.items_filtered++;
            pthread_mutex_unlock(&pipeline_stats.stats_mutex);
        }
        
        if ((tick + 1) % 100 == 0) {
            printf("[Etapa %ld] Procesados %d items, %d v√°lidos (%.1f%%), suma=%.2f\n", 
                   stage_id, tick + 1, filtered_count, 
                   100.0 * filtered_count / (tick + 1), accumulated_result);
        }
        
        // Sincronizaci√≥n con barrier
        pthread_mutex_lock(&pipeline_stats.stats_mutex);
        pipeline_stats.barrier_waits++;
        pthread_mutex_unlock(&pipeline_stats.stats_mutex);
        
        pthread_barrier_wait(&pipeline_barrier);
    }
    
    printf("[Etapa %ld - Filtro/Reduce] Completado\n", stage_id);
    printf("  Items v√°lidos: %d\n", filtered_count);
    printf("  Resultado acumulado: %.6f\n", accumulated_result);
    
    return nullptr;
}

// ============================================================================
// CONTROL DE SHUTDOWN GRACEFUL
// ============================================================================

void request_pipeline_shutdown() {
    pthread_mutex_lock(&shutdown_mutex);
    pipeline_shutdown = true;
    pthread_mutex_unlock(&shutdown_mutex);
    
    // Despertar todos los hilos esperando en condiciones
    pthread_cond_broadcast(&buffer1_not_empty);
    pthread_cond_broadcast(&buffer1_not_full);
    pthread_cond_broadcast(&buffer2_not_empty);
    pthread_cond_broadcast(&buffer2_not_full);
    
    printf("üõë Shutdown del pipeline solicitado\n");
}

// ============================================================================
// FUNCI√ìN PRINCIPAL Y BENCHMARKS
// ============================================================================

void run_pipeline_benchmark(int num_ticks) {
    printf("============================================================\n");
    printf("üè≠ EJECUTANDO PIPELINE BENCHMARK\n");
    printf("============================================================\n");
    printf("Configuraci√≥n: %d ticks por etapa\n", num_ticks);
    
    // Reinicializar barrier para 3 etapas
    pthread_barrier_init(&pipeline_barrier, nullptr, 3);
    
    // Reset de variables globales
    pipeline_shutdown = false;
    pipeline_stats = PipelineStats{};
    
    // Crear hilos para cada etapa del pipeline
    pthread_t generator_thread, processor_thread, filter_thread;
    
    auto start_time = std::chrono::steady_clock::now();
    
    // Crear etapas del pipeline
    pthread_create(&generator_thread, nullptr, stage_generator, reinterpret_cast<void*>(1));
    pthread_create(&processor_thread, nullptr, stage_processor, reinterpret_cast<void*>(2));
    pthread_create(&filter_thread, nullptr, stage_filter_reduce, reinterpret_cast<void*>(3));
    
    printf("üöÄ Pipeline iniciado con 3 etapas\n");
    
    // Esperar terminaci√≥n de todas las etapas
    pthread_join(generator_thread, nullptr);
    printf("‚úÖ Etapa generadora terminada\n");
    
    pthread_join(processor_thread, nullptr);
    printf("‚úÖ Etapa procesadora terminada\n");
    
    pthread_join(filter_thread, nullptr);
    printf("‚úÖ Etapa filtro/reduce terminada\n");
    
    auto end_time = std::chrono::steady_clock::now();
    auto total_duration = std::chrono::duration<double>(end_time - start_time).count();
    
    printf("\n‚è±Ô∏è  RESULTADOS DEL BENCHMARK\n");
    printf("Tiempo total de ejecuci√≥n: %.3f segundos\n", total_duration);
    printf("Throughput del pipeline: %.2f items/seg\n", 
           pipeline_stats.items_generated / total_duration);
    printf("Eficiencia de filtrado: %.1f%%\n", 
           100.0 * pipeline_stats.items_filtered / pipeline_stats.items_generated);
    
    // Mostrar estad√≠sticas detalladas
    pipeline_stats.print_final_stats();
    
    // Verificar balance del pipeline
    printf("\nüìä AN√ÅLISIS DE BALANCE:\n");
    if (pipeline_stats.items_generated > pipeline_stats.items_processed + 50) {
        printf("‚ö†Ô∏è  Etapa procesadora es cuello de botella\n");
    } else if (pipeline_stats.items_processed > pipeline_stats.items_filtered + 50) {
        printf("‚ö†Ô∏è  Etapa filtro es cuello de botella\n");
    } else {
        printf("‚úÖ Pipeline bien balanceado\n");
    }
    
    // Cleanup del barrier
    pthread_barrier_destroy(&pipeline_barrier);
}

int main(int argc, char** argv) {
    printf("=== LABORATORIO 6 - PR√ÅCTICA 5: PIPELINE CON BARRERAS ===\n");
    
    int num_ticks = (argc > 1) ? std::atoi(argv[1]) : DEFAULT_TICKS;
    printf("Configuraci√≥n: %d ticks por etapa\n", num_ticks);
    
    // Crear directorio de datos si no existe
    system("mkdir -p data");
    
    // Ejecutar benchmark del pipeline
    run_pipeline_benchmark(num_ticks);
    
    printf("============================================================\n");
    printf("=== AN√ÅLISIS DE DISE√ëO ===\n");
    printf("============================================================\n");
    
    printf("üîÑ BARRERAS vs COLAS:\n");
    printf("‚Ä¢ Barreras: Sincronizaci√≥n por lotes (batch processing)\n");
    printf("  + Garantiza procesamiento en lockstep\n");
    printf("  + F√°cil de debuggear y medir\n");
    printf("  - Menor throughput por esperas\n");
    printf("  - El m√°s lento determina la velocidad total\n\n");
    
    printf("‚Ä¢ Colas: Procesamiento continuo (streaming)\n");
    printf("  + Mayor throughput al evitar esperas\n");
    printf("  + Mejor utilizaci√≥n de recursos\n");
    printf("  - M√°s complejo de sincronizar\n");
    printf("  - Posibles desbalances entre etapas\n\n");
    
    printf("‚ö° MEDICI√ìN DE THROUGHPUT POR ETAPA:\n");
    printf("‚Ä¢ Usar timestamps en DataItem para medir latencias\n");
    printf("‚Ä¢ Contadores at√≥micos para operaciones completadas\n");
    printf("‚Ä¢ Muestreo peri√≥dico para detectar cuellos de botella\n\n");
    
    printf("üõë GRACEFUL SHUTDOWN:\n");
    printf("‚Ä¢ Bandera global de shutdown\n");
    printf("‚Ä¢ Broadcast a todas las condition variables\n");
    printf("‚Ä¢ Timeout en operaciones de buffer\n");
    printf("‚Ä¢ Join de todos los hilos antes de limpiar recursos\n\n");
    
    printf("üîß PTHREAD_ONCE:\n");
    printf("‚Ä¢ Garantiza inicializaci√≥n √∫nica de recursos costosos\n");
    printf("‚Ä¢ Thread-safe sin overhead de mutex en llamadas subsecuentes\n");
    printf("‚Ä¢ √ötil para: abrir archivos, precomputar tablas, init RNG\n\n");
    
    printf("=== PREGUNTAS GU√çA RESPONDIDAS ===\n");
    printf("‚Ä¢ ¬øD√≥nde conviene barrera vs colas?\n");
    printf("  ‚Üí Barreras para debugging y an√°lisis, colas para producci√≥n\n");
    printf("‚Ä¢ ¬øC√≥mo medir throughput por etapa?\n");
    printf("  ‚Üí Timestamps + contadores at√≥micos + sampling peri√≥dico\n");
    printf("‚Ä¢ ¬øC√≥mo graceful shutdown sin deadlocks?\n");
    printf("  ‚Üí Bandera global + timeouts + broadcast + join ordenado\n");
    
    // Cleanup de recursos globales
    if (log_file) {
        log_file->close();
        delete log_file;
    }
    if (global_rng) {
        delete global_rng;
    }
    if (lookup_table) {
        delete[] lookup_table;
    }
    
    // Cleanup de primitivas de sincronizaci√≥n
    pthread_mutex_destroy(&buffer1_mutex);
    pthread_mutex_destroy(&buffer2_mutex);
    pthread_mutex_destroy(&shutdown_mutex);
    pthread_mutex_destroy(&pipeline_stats.stats_mutex);
    pthread_cond_destroy(&buffer1_not_empty);
    pthread_cond_destroy(&buffer1_not_full);
    pthread_cond_destroy(&buffer2_not_empty);
    pthread_cond_destroy(&buffer2_not_full);
    
    printf("\n‚úÖ Programa terminado exitosamente\n");
    printf("üìÑ Log generado en: data/pipeline_log.txt\n");
    
    return 0;
}